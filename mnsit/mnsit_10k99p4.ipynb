{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnsit_10k99p4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIAERUnwvLpD"
      },
      "source": [
        "*Write a DNN of Google Colab: 1. It must have less than 11000 parameters. 2. Achieve 99.4% validation accuracy on MNIST*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt"
      },
      "source": [
        "# https://keras.io/\n",
        "# The following cell downloads keras for the Google Colab session\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4"
      },
      "source": [
        "# Importing numpy library and the required modules from Keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUW6W2rNd7FL"
      },
      "source": [
        "The cell below loads the MNIST database of handwritten digits (which comprises of a development set of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images). load_data() function of mnist class returns two tuples (x_train, y_train) and (x_test, y_test), where <br>\n",
        "x_train | x_test  : uint8 array of grayscale image data with shape (60000, 28, 28) | (10000, 28, 28) respectively <br>\n",
        "y_train | y_test : uint8 array of digit labels (integers in range 0-9) with shape (60000,) | (10000,) respectively <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abfd7275-1fd5-416c-d3c6-57e93dbe0bb5"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "b4b2a37f-58bb-4ce5-9396-a7da5bf62203"
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9478c6c470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ"
      },
      "source": [
        "# Reshaping the images from 28x28 to 28x28x1, thus making the shape of the array contain channel information\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKOS2v2oeHFR"
      },
      "source": [
        "Grayscale are encoded as 8-bit integers, which range from 0 to 255. \n",
        "Normalizing the values of the these pixels in the image from (0,255) to (0,1) helps in obtaining easily to handle and/or easily visualizable values for loss, learning rate etc.,   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0eafc2e-30ca-4641-bb93-a10c57c4684f"
      },
      "source": [
        "y_train[:10] # Prints integer label values of first 10 images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfy47975eLj8"
      },
      "source": [
        "Converting integer labels into one-hot encodings as to make the label dimension same as the number of output neurons (needed to apply cross-entropy loss as the latter works on probability distributions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC"
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b1f426f-7d08-4c8c-ae5c-3a7854e922ed"
      },
      "source": [
        "Y_train[:10] # Prints one hot label values of first 10 images\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb3dMoWSeWI1"
      },
      "source": [
        "--------------------------------------\n",
        "Equation of the [Softmax function](https://en.wikipedia.org/wiki/Softmax_function 'Click here to learn more about the Softmax fn')\n",
        " performed on the j<sup>th</sup> output of the model defined in the cell below : \n",
        "$$ P(y = j | x) = \\frac{e^{x^{T}.w_j}}{\\sum_{k = 1}^{K} e^{x^{T}.w_k}} $$\n",
        "\n",
        "where   x : input image \\\n",
        "&emsp; &emsp; &nbsp; w : parameters of the model (weights) \\\n",
        "&emsp; &emsp; &nbsp; K : number of output neurons on the network <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr__8Bt3fSS-"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(8, kernel_size = 3, strides = 1, input_shape=(28,28,1)))                       # Channel : 26x26x8 , RF : 3x3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(12, kernel_size = 3, strides = 1))                                             # Channel : 24x24x12 , RF : 5x5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1)) \n",
        "   \n",
        "model.add(Convolution2D(12, kernel_size = 3, strides = 1))                                             # Channel : 22x22x16 , RF : 7x7\n",
        "model.add(BatchNormalization()) \n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))                    \n",
        "         \n",
        "model.add(MaxPooling2D(2))                                                                             # Channel : 11x11x16 , RF : 14x14\n",
        "          \n",
        "model.add(Convolution2D(12, kernel_size = 3, strides = 1))                                             # Channel : 9x9x20 , RF : 16x16\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1)) \n",
        "\n",
        "model.add(Convolution2D(16, kernel_size = 3, strides = 1))                                             # Channel : 7x7x24 , RF : 18x18\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1)) \n",
        "          \n",
        "model.add(Convolution2D(10, 1))                                                                        # Channel : 7x7x10 , RF : 18x18\n",
        "\n",
        "model.add(Convolution2D(10, 7))                                                                        # Channel : 1x1x10 , RF : FULL\n",
        "model.add(Flatten()) # Converts shape (1,1,10) to (10,)\n",
        "model.add(Activation('softmax')) # The outputs are subjected to a softmax in order to make the latter into a sum-to-1 \\\n",
        "                                 #     posterior distribution, as this will be the output to cross-entropy loss. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca79a2e1-97f7-437b-9e8d-a5be5fccdd56"
      },
      "source": [
        "model.summary() # Prints the summary of the Sequential model created"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 12)        876       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 12)        48        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 12)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 24, 24, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 12)        1308      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 22, 22, 12)        48        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 22, 22, 12)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 22, 22, 12)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 11, 11, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 12)          1308      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 9, 9, 12)          48        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 9, 9, 12)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 9, 9, 12)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 16)          1744      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,636\n",
            "Trainable params: 10,516\n",
            "Non-trainable params: 120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdOLFAtwFuEt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anyTCCxEe06K"
      },
      "source": [
        "Equation of [Cross-entropy loss](https://en.wikipedia.org/wiki/Cross_entropy 'Click here to learn more about cross entropy loss') function used below while compiling : <br><br>\n",
        "$$ H(p,q) = -\\sum_{x \\epsilon X} p(x) \\text{log}  q(x) $$\n",
        "\n",
        "where q(x) : predicted probability distribution \\\n",
        "&emsp; &emsp; &nbsp; p(x) : target probability distribution\n",
        "\n",
        "----------------------------\n",
        "\n",
        "[Adam optimizer](https://arxiv.org/abs/1412.6980 'Click here to learn more about Adam optimizer') : gradient-based optimizer used in iterative update of network weights. Default learning rate, as used here, of Keras' Adam optimizer is 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h"
      },
      "source": [
        "# compile function of model class configures the network for training. \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crk6mg0iLhDM",
        "outputId": "87f2fb3c-19de-4a08-8793-dc3d638f181b"
      },
      "source": [
        "# fit function of model class trains the model for a given number of epochs (here 10) and given batch size (here 20)\r\n",
        "model.fit(X_train, Y_train, batch_size=20, epochs=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3000/3000 [==============================] - 18s 4ms/step - loss: 0.3801 - accuracy: 0.8789\n",
            "Epoch 2/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0744 - accuracy: 0.9768\n",
            "Epoch 3/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0551 - accuracy: 0.9827\n",
            "Epoch 4/20\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0468 - accuracy: 0.9853\n",
            "Epoch 5/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0430 - accuracy: 0.9866\n",
            "Epoch 6/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0349 - accuracy: 0.9887\n",
            "Epoch 7/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0350 - accuracy: 0.9891\n",
            "Epoch 8/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0317 - accuracy: 0.9894\n",
            "Epoch 9/20\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0298 - accuracy: 0.9909\n",
            "Epoch 10/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0311 - accuracy: 0.9901\n",
            "Epoch 11/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0263 - accuracy: 0.9911\n",
            "Epoch 12/20\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0288 - accuracy: 0.9906\n",
            "Epoch 13/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0250 - accuracy: 0.9919\n",
            "Epoch 14/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0286 - accuracy: 0.9913\n",
            "Epoch 15/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0258 - accuracy: 0.9918\n",
            "Epoch 16/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0262 - accuracy: 0.9918\n",
            "Epoch 17/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0246 - accuracy: 0.9920\n",
            "Epoch 18/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0213 - accuracy: 0.9934\n",
            "Epoch 19/20\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0202 - accuracy: 0.9931\n",
            "Epoch 20/20\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0209 - accuracy: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f941e4356d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77956b4-247d-4fdf-8db2-f72b8c074716"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=20, epochs=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0149 - accuracy: 0.9949\n",
            "Epoch 2/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0147 - accuracy: 0.9952\n",
            "Epoch 3/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0161 - accuracy: 0.9948\n",
            "Epoch 4/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0158 - accuracy: 0.9948\n",
            "Epoch 5/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0145 - accuracy: 0.9953\n",
            "Epoch 6/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0149 - accuracy: 0.9950\n",
            "Epoch 7/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0149 - accuracy: 0.9948\n",
            "Epoch 8/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0144 - accuracy: 0.9953\n",
            "Epoch 9/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0142 - accuracy: 0.9951\n",
            "Epoch 10/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0140 - accuracy: 0.9954\n",
            "Epoch 11/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0143 - accuracy: 0.9950\n",
            "Epoch 12/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0140 - accuracy: 0.9956\n",
            "Epoch 13/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0147 - accuracy: 0.9949\n",
            "Epoch 14/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0127 - accuracy: 0.9954\n",
            "Epoch 15/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0145 - accuracy: 0.9951\n",
            "Epoch 16/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0138 - accuracy: 0.9954\n",
            "Epoch 17/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0143 - accuracy: 0.9953\n",
            "Epoch 18/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0129 - accuracy: 0.9953\n",
            "Epoch 19/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0136 - accuracy: 0.9955\n",
            "Epoch 20/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0129 - accuracy: 0.9956\n",
            "Epoch 21/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0137 - accuracy: 0.9952\n",
            "Epoch 22/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0123 - accuracy: 0.9956\n",
            "Epoch 23/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0130 - accuracy: 0.9953\n",
            "Epoch 24/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0136 - accuracy: 0.9955\n",
            "Epoch 25/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0121 - accuracy: 0.9959\n",
            "Epoch 26/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0134 - accuracy: 0.9953\n",
            "Epoch 27/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0130 - accuracy: 0.9956\n",
            "Epoch 28/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0139 - accuracy: 0.9953\n",
            "Epoch 29/30\n",
            "3000/3000 [==============================] - 10s 3ms/step - loss: 0.0121 - accuracy: 0.9959\n",
            "Epoch 30/30\n",
            "3000/3000 [==============================] - 11s 4ms/step - loss: 0.0118 - accuracy: 0.9961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f941e0b2400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds8hbOxxQgu7",
        "outputId": "f0ac7de9-5faa-433f-e37e-855827d0095f"
      },
      "source": [
        "# evaluate function performs a forward pass in test mode and returns loss value and accuracy for X_test images passed below\r\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\r\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02561553381383419, 0.9940000176429749]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh"
      },
      "source": [
        "# predict function generates output predictions for X_test images passed below\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5614c3f4-1135-4cd5-fc64-2e85022cd451"
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.41125870e-12 7.00172906e-12 1.08572906e-09 8.73998740e-09\n",
            "  1.96122873e-14 3.43291548e-15 4.32775189e-18 1.00000000e+00\n",
            "  2.79179132e-12 8.68552563e-10]\n",
            " [6.17879498e-11 4.30238911e-09 1.00000000e+00 4.34577244e-12\n",
            "  3.07689789e-12 1.11115931e-15 2.59705521e-11 1.82721297e-13\n",
            "  1.72336659e-10 6.44821831e-15]\n",
            " [4.64226702e-08 9.99999166e-01 2.96846464e-10 1.26694460e-10\n",
            "  5.32995614e-07 1.36164191e-09 3.43295739e-08 2.16041670e-07\n",
            "  1.13879794e-08 4.69319161e-08]\n",
            " [9.99999881e-01 1.11761876e-11 4.99798380e-09 5.64815486e-11\n",
            "  6.76489698e-11 2.19926077e-09 1.65783945e-07 7.38583934e-12\n",
            "  3.50696432e-08 1.65297767e-08]\n",
            " [6.63556612e-13 3.21306133e-13 2.52160247e-15 1.60166205e-13\n",
            "  9.99998331e-01 4.94965397e-15 5.22511374e-12 1.61413884e-12\n",
            "  9.49508527e-12 1.63779998e-06]\n",
            " [9.61970059e-09 9.99983788e-01 1.58679825e-08 2.37352707e-11\n",
            "  8.39354243e-07 1.62958952e-11 6.64126931e-09 1.51084696e-05\n",
            "  5.72583403e-08 1.60182708e-07]\n",
            " [6.84484586e-22 4.59636235e-13 9.30240104e-17 1.13992794e-16\n",
            "  9.99999404e-01 3.28270329e-14 2.85194732e-18 2.72467687e-10\n",
            "  8.23330293e-09 5.74589762e-07]\n",
            " [6.38120676e-12 6.97386203e-12 3.19468031e-13 1.27463234e-10\n",
            "  6.06535395e-05 4.06917763e-11 1.62277616e-16 4.23632462e-10\n",
            "  1.14861782e-08 9.99939322e-01]\n",
            " [4.13189510e-10 8.64493806e-13 3.37479305e-14 4.74006359e-13\n",
            "  1.13131510e-15 9.99979138e-01 2.01436214e-05 7.32592189e-15\n",
            "  5.06560298e-07 2.01106033e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cc5a83-3148-4309-cd21-4900e196766a"
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "print(layer_dict)\n",
        "layer_dict['conv2d_6'].output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'conv2d': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9477a768d0>, 'batch_normalization': <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f9477a84e10>, 'activation': <tensorflow.python.keras.layers.core.Activation object at 0x7f9477a84d68>, 'dropout': <tensorflow.python.keras.layers.core.Dropout object at 0x7f94600b4208>, 'conv2d_1': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f94600c0c50>, 'batch_normalization_1': <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f94600c7e80>, 'activation_1': <tensorflow.python.keras.layers.core.Activation object at 0x7f9460052ba8>, 'dropout_1': <tensorflow.python.keras.layers.core.Dropout object at 0x7f9460052cf8>, 'conv2d_2': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9460063470>, 'batch_normalization_2': <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f9460063ef0>, 'activation_2': <tensorflow.python.keras.layers.core.Activation object at 0x7f9460063f28>, 'dropout_2': <tensorflow.python.keras.layers.core.Dropout object at 0x7f9460069f98>, 'max_pooling2d': <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f9460073d30>, 'conv2d_3': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9460079748>, 'batch_normalization_3': <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f94600794a8>, 'activation_3': <tensorflow.python.keras.layers.core.Activation object at 0x7f94600792e8>, 'dropout_3': <tensorflow.python.keras.layers.core.Dropout object at 0x7f9460069dd8>, 'conv2d_4': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f94600c00b8>, 'batch_normalization_4': <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f9460052240>, 'activation_4': <tensorflow.python.keras.layers.core.Activation object at 0x7f94600522e8>, 'dropout_4': <tensorflow.python.keras.layers.core.Dropout object at 0x7f94600fd9b0>, 'conv2d_5': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f94600b4c88>, 'conv2d_6': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9460080be0>, 'flatten': <tensorflow.python.keras.layers.core.Flatten object at 0x7f9460080240>, 'activation_5': <tensorflow.python.keras.layers.core.Activation object at 0x7f9460080470>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 1, 1, 10) dtype=float32 (created by layer 'conv2d_6')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}