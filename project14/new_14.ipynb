{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOsYqWHvQBrZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, math\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcVY1UhnQPDO"
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnXG0ogqr5P3"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "K.set_floatx('float16')\n",
    "K.set_epsilon(1e-5) #default is 1e-7\n",
    "isTestMode = False #use this for training short epochs to quickly see the results\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LfLeMAyQU7z"
   },
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 512 #@param {type:\"integer\"}\n",
    "BATCH_SIZE = 128\n",
    "MOMENTUM = 0.9 #@param {type:\"number\"}\n",
    "LEARNING_RATE = 0.4 #@param {type:\"number\"}\n",
    "WEIGHT_DECAY = 5e-4 #@param {type:\"number\"}\n",
    "#EPOCHS = 24 #@param {type:\"integer\"}\n",
    "EPOCHS = 24\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWMF8JptnCnM"
   },
   "outputs": [],
   "source": [
    "## 2\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization, Layer,InputSpec\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.initializers import Initializer\n",
    "from tensorflow.python.keras.backend  import  _regular_normalize_batch_in_training\n",
    "\n",
    "\n",
    "#custom initializers to force float32\n",
    "class Ones32(Initializer):\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        return K.constant(1, shape=shape, dtype='float32')\n",
    "\n",
    "class Zeros32(Initializer):\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        return K.constant(0, shape=shape, dtype='float32')\n",
    "    \n",
    "\n",
    "\n",
    "class BatchNormalizationF16(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 axis=-1,\n",
    "                 momentum=0.99,\n",
    "                 epsilon=1e-3,\n",
    "                 center=True,\n",
    "                 scale=True,\n",
    "                 beta_initializer='zeros',\n",
    "                 gamma_initializer='ones',\n",
    "                 moving_mean_initializer='zeros',\n",
    "                 moving_variance_initializer='ones',\n",
    "                 beta_regularizer=None,\n",
    "                 gamma_regularizer=None,\n",
    "                 beta_constraint=None,\n",
    "                 gamma_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(BatchNormalizationF16, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.axis = axis\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.beta_initializer = initializers.get(beta_initializer)\n",
    "        self.gamma_initializer = initializers.get(gamma_initializer)\n",
    "        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n",
    "        self.moving_variance_initializer = (\n",
    "            initializers.get(moving_variance_initializer))\n",
    "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
    "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
    "        self.beta_constraint = constraints.get(beta_constraint)\n",
    "        self.gamma_constraint = constraints.get(gamma_constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        dim = input_shape[self.axis]\n",
    "        if dim is None:\n",
    "            raise ValueError('Axis ' + str(self.axis) + ' of '\n",
    "                             'input tensor should have a defined dimension '\n",
    "                             'but the layer received an input with shape ' +\n",
    "                             str(input_shape) + '.')\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape),\n",
    "                                    axes={self.axis: dim})\n",
    "        shape = (dim,)\n",
    "\n",
    "        if self.scale:\n",
    "            self.gamma = self.add_weight(shape=shape,\n",
    "                                         name='gamma',\n",
    "                                         initializer=self.gamma_initializer,\n",
    "                                         regularizer=self.gamma_regularizer,\n",
    "                                         constraint=self.gamma_constraint)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "        if self.center:\n",
    "            self.beta = self.add_weight(shape=shape,\n",
    "                                        name='beta',\n",
    "                                        initializer=self.beta_initializer,\n",
    "                                        regularizer=self.beta_regularizer,\n",
    "                                        constraint=self.beta_constraint)\n",
    "        else:\n",
    "            self.beta = None\n",
    "        self.moving_mean = self.add_weight(\n",
    "            shape=shape,\n",
    "            name='moving_mean',\n",
    "            initializer=self.moving_mean_initializer,\n",
    "            trainable=False)\n",
    "        self.moving_variance = self.add_weight(\n",
    "            shape=shape,\n",
    "            name='moving_variance',\n",
    "            initializer=self.moving_variance_initializer,\n",
    "            trainable=False)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        # Prepare broadcasting shape.\n",
    "        ndim = len(input_shape)\n",
    "        reduction_axes = list(range(len(input_shape)))\n",
    "        del reduction_axes[self.axis]\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        # Determines whether broadcasting is needed.\n",
    "        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n",
    "\n",
    "        def normalize_inference():\n",
    "            if needs_broadcasting:\n",
    "                # In this case we must explicitly broadcast all parameters.\n",
    "                broadcast_moving_mean = K.reshape(self.moving_mean,\n",
    "                                                  broadcast_shape)\n",
    "                broadcast_moving_variance = K.reshape(self.moving_variance,\n",
    "                                                      broadcast_shape)\n",
    "                if self.center:\n",
    "                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
    "                else:\n",
    "                    broadcast_beta = None\n",
    "                if self.scale:\n",
    "                    broadcast_gamma = K.reshape(self.gamma,\n",
    "                                                broadcast_shape)\n",
    "                else:\n",
    "                    broadcast_gamma = None\n",
    "                return tf.nn.batch_normalization(#K.batch_normalization(\n",
    "                    inputs,\n",
    "                    broadcast_moving_mean,\n",
    "                    broadcast_moving_variance,\n",
    "                    broadcast_beta,\n",
    "                    broadcast_gamma,\n",
    "                    #axis=self.axis,\n",
    "                    self.epsilon)#epsilon=self.epsilon)\n",
    "            else:\n",
    "                return tf.nn.batch_normalization(#K.batch_normalization(\n",
    "                    inputs,\n",
    "                    self.moving_mean,\n",
    "                    self.moving_variance,\n",
    "                    self.beta,\n",
    "                    self.gamma,\n",
    "                    #axis=self.axis,\n",
    "                    self.epsilon)#epsilon=self.epsilon)\n",
    "\n",
    "        # If the learning phase is *static* and set to inference:\n",
    "        if training in {0, False}:\n",
    "            return normalize_inference()\n",
    "\n",
    "        # If the learning is either dynamic, or set to training:\n",
    "        normed_training, mean, variance = _regular_normalize_batch_in_training(#K.normalize_batch_in_training(\n",
    "            inputs, self.gamma, self.beta, reduction_axes,\n",
    "            epsilon=self.epsilon)\n",
    "\n",
    "        if K.backend() != 'cntk':\n",
    "            sample_size = K.prod([K.shape(inputs)[axis]\n",
    "                                  for axis in reduction_axes])\n",
    "            sample_size = K.cast(sample_size, dtype=K.dtype(inputs))\n",
    "\n",
    "            # sample variance - unbiased estimator of population variance\n",
    "            variance *= sample_size / (sample_size - (1.0 + self.epsilon))\n",
    "\n",
    "        self.add_update([K.moving_average_update(self.moving_mean,\n",
    "                                                 mean,\n",
    "                                                 self.momentum),\n",
    "                         K.moving_average_update(self.moving_variance,\n",
    "                                                 variance,\n",
    "                                                 self.momentum)],\n",
    "                        inputs)\n",
    "\n",
    "        # Pick the normalized form corresponding to the training phase.\n",
    "        return K.in_train_phase(normed_training,\n",
    "                                normalize_inference,\n",
    "                                training=training)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'axis': self.axis,\n",
    "            'momentum': self.momentum,\n",
    "            'epsilon': self.epsilon,\n",
    "            'center': self.center,\n",
    "            'scale': self.scale,\n",
    "            'beta_initializer': initializers.serialize(self.beta_initializer),\n",
    "            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n",
    "            'moving_mean_initializer':\n",
    "                initializers.serialize(self.moving_mean_initializer),\n",
    "            'moving_variance_initializer':\n",
    "                initializers.serialize(self.moving_variance_initializer),\n",
    "            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n",
    "            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n",
    "            'beta_constraint': constraints.serialize(self.beta_constraint),\n",
    "            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n",
    "        }\n",
    "        base_config = super(BatchNormalizationF16, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwS9BRv_QWR0"
   },
   "outputs": [],
   "source": [
    "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
    "  fan = np.prod(shape[:-1])\n",
    "  bound = 1 / math.sqrt(fan)\n",
    "  return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQdPrpJ8QXvy"
   },
   "outputs": [],
   "source": [
    "class ConvBN(tf.keras.Model):\n",
    "  def __init__(self, c_out):\n",
    "    super().__init__()\n",
    "    self.conv = tf.keras.layers.Conv2D(filters=c_out, kernel_size=3, padding=\"SAME\", kernel_initializer=init_pytorch, use_bias=False)\n",
    "    self.bn = BatchNormalizationF16(momentum=0.9, epsilon=1e-5)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.nn.relu(self.bn(self.conv(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBuqNlb7QZc9"
   },
   "outputs": [],
   "source": [
    "class ResBlk(tf.keras.Model):\n",
    "  def __init__(self, c_out, pool, res = False):\n",
    "    super().__init__()\n",
    "    self.conv_bn = ConvBN(c_out)\n",
    "    self.pool = pool\n",
    "    self.res = res\n",
    "    if self.res:\n",
    "      self.res1 = ConvBN(c_out)\n",
    "      self.res2 = ConvBN(c_out)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    h = self.pool(self.conv_bn(inputs))\n",
    "    if self.res:\n",
    "      h = h + self.res2(self.res1(h))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uB5ENbbjQa7r"
   },
   "outputs": [],
   "source": [
    "class DavidNet(tf.keras.Model):\n",
    "  def __init__(self, c=64, weight=0.125):\n",
    "    super().__init__()\n",
    "    pool = tf.keras.layers.MaxPooling2D()\n",
    "    self.init_conv_bn = ConvBN(c)\n",
    "    self.blk1 = ResBlk(c*2, pool, res = True)\n",
    "    self.blk2 = ResBlk(c*4, pool)\n",
    "    self.blk3 = ResBlk(c*8, pool, res = True)\n",
    "    self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
    "    self.linear = tf.keras.layers.Dense(10, kernel_initializer=init_pytorch, use_bias=False)\n",
    "    self.weight = weight\n",
    "\n",
    "  def call(self, x, y):\n",
    "    h = self.pool(self.blk3(self.blk2(self.blk1(self.init_conv_bn(x)))))\n",
    "    h = self.linear(h) * self.weight\n",
    "    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h, labels=y)\n",
    "    loss = tf.reduce_sum(ce)\n",
    "    correct = tf.reduce_sum(tf.cast(tf.math.equal(tf.argmax(h, axis = 1), y), tf.float32))\n",
    "    return loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQC9BguoQcfp"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "len_train, len_test = len(x_train), len(x_test)\n",
    "y_train = y_train.astype('int64').reshape(len_train)\n",
    "y_test = y_test.astype('int64').reshape(len_test)\n",
    "\n",
    "train_mean = np.mean(x_train, axis=(0,1,2))\n",
    "train_std = np.std(x_train, axis=(0,1,2))\n",
    "\n",
    "normalize = lambda x: ((x - train_mean) / train_std).astype('float32') # todo: check here\n",
    "pad4 = lambda x: np.pad(x, [(0, 0), (4, 4), (4, 4), (0, 0)], mode='reflect')\n",
    "\n",
    "x_train = normalize(pad4(x_train))\n",
    "x_test = normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejgtotCur97c"
   },
   "outputs": [],
   "source": [
    "## mean and sd\n",
    "X_train_mean = np.mean(x_train, axis=(0,1,2))\n",
    "X_train_std = np.std(x_train, axis=(0,1,2))\n",
    "X_train = (x_train - X_train_mean) / X_train_std\n",
    "X_test = (x_test - X_train_mean) / X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XyN5gL4wnefO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## 3\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1zZKYFgsuJ4"
   },
   "outputs": [],
   "source": [
    "## Cutout\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-rBodFhQeNZ"
   },
   "outputs": [],
   "source": [
    "model = DavidNet()\n",
    "batches_per_epoch = len_train//BATCH_SIZE + 1\n",
    "\n",
    "lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, EPOCHS], [0, LEARNING_RATE, 0])[0]\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "lr_func = lambda: lr_schedule(global_step/batches_per_epoch)/BATCH_SIZE\n",
    "opt = tf.train.MomentumOptimizer(lr_func, momentum=MOMENTUM, use_nesterov=True)\n",
    "data_aug = lambda x, y: (tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3])), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sL7hGy_uTkw"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#datagen = ImageDataGenerator(zoom_range=0.0, \n",
    " #                            horizontal_flip=False)\n",
    "                             \n",
    "datagen = ImageDataGenerator(zoom_range=0.0, \n",
    "                             horizontal_flip=False,\n",
    "                             preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "colab_type": "code",
    "id": "Eeqp9zgtQjQN",
    "outputId": "df6a90b8-c2bf-476b-ba37-64416ae310f0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f073ff9a6e7449bb2b63a0816fdb31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1 lr: 0.08 train loss: 1.2649048085021972 train acc: 0.54424 val loss: 0.7920963552474976 val acc: 0.7208 time: 79.12357211112976\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a2f22b09b947dcbae00393e39feb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2 lr: 0.16 train loss: 0.7304221697998047 train acc: 0.74746 val loss: 0.6840346492767334 val acc: 0.7595 time: 153.5100212097168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397cf334b0864758be25dd9a821ef677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3 lr: 0.24 train loss: 0.5975136457061767 train acc: 0.79286 val loss: 0.5731788343429566 val acc: 0.8101 time: 227.3521683216095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d98768a65f4154bed65a8bcdfdfc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4 lr: 0.32 train loss: 0.508882004776001 train acc: 0.82436 val loss: 0.4763436237335205 val acc: 0.8395 time: 300.91584396362305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fec8844a2dd4a25bffd57ec015e5d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 5 lr: 0.4 train loss: 0.4373853779602051 train acc: 0.84936 val loss: 0.43310517501831053 val acc: 0.8501 time: 375.4254596233368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243b761377d143a28dbcaf0a16404361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 6 lr: 0.37894736842105264 train loss: 0.3694061469268799 train acc: 0.87272 val loss: 0.38490452489852905 val acc: 0.8694 time: 450.95139479637146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78548333705478890a1f424fc53dbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 7 lr: 0.35789473684210527 train loss: 0.31078537811279294 train acc: 0.89262 val loss: 0.34070136580467225 val acc: 0.8857 time: 525.2462010383606\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6341c97b3d8a4be8904112b1f3f9ff86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 8 lr: 0.33684210526315794 train loss: 0.26598099815368653 train acc: 0.90742 val loss: 0.3158857133150101 val acc: 0.8926 time: 598.8384323120117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c43588e70e44b05a9d602c58a21e11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 9 lr: 0.31578947368421056 train loss: 0.23034393327713013 train acc: 0.92 val loss: 0.30046379442214965 val acc: 0.8987 time: 672.4732441902161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd1db0d855d4ef1baddf9e879511e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 10 lr: 0.2947368421052632 train loss: 0.19522554990768431 train acc: 0.93206 val loss: 0.2981162580013275 val acc: 0.9049 time: 745.3828284740448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0a9b704c274ea98fa155bdf5f8df1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 11 lr: 0.2736842105263158 train loss: 0.16983652507781982 train acc: 0.94024 val loss: 0.29724221687316893 val acc: 0.9066 time: 819.7301468849182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97353743ed5746d6ae3047d426c4be7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 12 lr: 0.25263157894736843 train loss: 0.14944424352645874 train acc: 0.94892 val loss: 0.29526279978752135 val acc: 0.9067 time: 893.075704574585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2d61dfba7640718e7b54a6eb17d5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 13 lr: 0.23157894736842108 train loss: 0.12459925051689148 train acc: 0.95652 val loss: 0.2775952754497528 val acc: 0.9141 time: 966.9181463718414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd2367f35e84033818c61d1b7947a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 14 lr: 0.2105263157894737 train loss: 0.10544498654365539 train acc: 0.9635 val loss: 0.2849283536911011 val acc: 0.9132 time: 1041.3282792568207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a4db8eb95343419dba9bbec488ff3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 15 lr: 0.18947368421052635 train loss: 0.09086465152740479 train acc: 0.9679 val loss: 0.28220213098526004 val acc: 0.9176 time: 1114.5095348358154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d11192dede4002992cb228ed98d27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 16 lr: 0.16842105263157897 train loss: 0.07464763734340668 train acc: 0.97466 val loss: 0.27987586040496826 val acc: 0.9193 time: 1187.2444591522217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c606ee6383487d9807ddede7f6ca4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 17 lr: 0.1473684210526316 train loss: 0.061997311491966245 train acc: 0.9791 val loss: 0.2741787225246429 val acc: 0.9204 time: 1260.7158660888672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2be04fe9964898a1eeb8ab781c7915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 18 lr: 0.12631578947368421 train loss: 0.048047000644207 train acc: 0.9842 val loss: 0.27074033546447757 val acc: 0.924 time: 1333.105589389801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72954beec919402d91b0f1a2d852809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 19 lr: 0.10526315789473689 train loss: 0.04061807505607605 train acc: 0.98634 val loss: 0.2691372907876968 val acc: 0.9268 time: 1407.5116505622864\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df860c267f24b688a869a5eee65bcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 20 lr: 0.08421052631578951 train loss: 0.0310743956387043 train acc: 0.99006 val loss: 0.2726139458179474 val acc: 0.9267 time: 1481.6646583080292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ed3a13548348b3b63c495352740686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 21 lr: 0.06315789473684214 train loss: 0.02409784118294716 train acc: 0.99296 val loss: 0.2722701672077179 val acc: 0.9266 time: 1555.9262738227844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66aa0cd628b64629bf2691f06324f078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 22 lr: 0.04210526315789476 train loss: 0.01987887993633747 train acc: 0.99438 val loss: 0.2664757676124573 val acc: 0.9287 time: 1630.5681366920471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6811abe0094a4089acd5dd61c378a987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 23 lr: 0.02105263157894738 train loss: 0.017519124902784823 train acc: 0.99482 val loss: 0.2623231911182404 val acc: 0.9321 time: 1704.0764377117157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5a3bdfcb744bedac09b538e7763de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 24 lr: 0.0 train loss: 0.01394220542371273 train acc: 0.99616 val loss: 0.2610576047897339 val acc: 0.9316 time: 1776.9598019123077\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  train_loss = test_loss = train_acc = test_acc = 0.0\n",
    "  train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(data_aug).shuffle(len_train).batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "  tf.keras.backend.set_learning_phase(1)\n",
    "  for (x, y) in tqdm(train_set):\n",
    "    with tf.GradientTape() as tape:\n",
    "      loss, correct = model(x, y)\n",
    "\n",
    "    var = model.trainable_variables\n",
    "    grads = tape.gradient(loss, var)\n",
    "    for g, v in zip(grads, var):\n",
    "      g += v * WEIGHT_DECAY * BATCH_SIZE\n",
    "    opt.apply_gradients(zip(grads, var), global_step=global_step)\n",
    "\n",
    "    train_loss += loss.numpy()\n",
    "    train_acc += correct.numpy()\n",
    "\n",
    "  tf.keras.backend.set_learning_phase(0)\n",
    "  for (x, y) in test_set:\n",
    "    loss, correct = model(x, y)\n",
    "    test_loss += loss.numpy()\n",
    "    test_acc += correct.numpy()\n",
    "    \n",
    "  print('epoch:', epoch+1, 'lr:', lr_schedule(epoch+1), 'train loss:', train_loss / len_train, 'train acc:', train_acc / len_train, 'val loss:', test_loss / len_test, 'val acc:', test_acc / len_test, 'time:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Copy of DN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
